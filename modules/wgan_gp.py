import tensorflow as tf
from tensorflow.keras.metrics import Mean


class WGANGP(tf.keras.Model):
    """
    Subclass of Keras `Model` implementing a GAN with Wasserstein loss and
    gradient penalty.

    Due to the custom nature of the model, which is in fact just a "container"
    for a `Critic`, a `Generator` and two optimizer objects, it needs custom
    `get_config` and `from_config` methods to be defined. In particular,
      * `get_config`: instance method that returns a dictionary that needs to
                      contain all the arguments (and corresponding objects)
                      needed to create an instance. In particular, since some
                      of these arguments are Keras `Model` objects themselves
                      (the critic and the generator), these needs to be
                      serialized. The structure of the config is
                        {'{arg_name}': object}
      * `from_config`: class method needed to generate an instance of `WGANGP`
                       from a saved model's config. It has the config
                       dictionary generated by `get_config` at saving time as
                       the input, from which it deserializes the serialized
                       objects, returning a class instance whose constructor
                       is passed exactly what was in the config itself.
    Saving/loading happens as usual with `Model.save` and
    `keras.models.load_models`.

    Note: the above saving/loading procedure IGNORES the optimizers, as the
          `compile` method for `WGANGP` is also custom, so the two optimizers
          are NOT SAVED at model saving time and thus NOT LOADED at model
          loading time.
          (With the usual behaviour, on the contrary, the standard `compile`
          method would create an `optimizer` attribute corresponding to the
          optimizer object, which would be serialized and deserialized
          automatically at saving and load time.).
    """
    def __init__(
        self,
        critic,
        generator,
        latent_dim,
        critic_steps,
        gp_weight
    ):
        """
        """
        super().__init__()

        self.critic = critic
        self.generator = generator

        self.latent_dim = latent_dim
        self.critic_steps = critic_steps
        self.gp_weight = gp_weight

    def get_config(self):
        """
        Generates the config for the model (needed for serialization/
        deserialization) and seralizes custom objects (layers, etc.).
        """
        base_config = super().get_config()

        config_extension = {
            'critic': tf.keras.saving.serialize_keras_object(self.critic),
            'generator': (
                tf.keras.saving.serialize_keras_object(self.generator)
            ),
            'latent_dim': self.latent_dim,
            'critic_steps': self.critic_steps,
            'gp_weight': self.gp_weight
        }

        return {**base_config, **config_extension}

    @classmethod
    def from_config(cls, config):
        """
        Generates a model from the config and the serialized custom objects.
        """
        # Deserialize `Critic` object.
        critic_config = config.pop('critic')
        critic = tf.keras.saving.deserialize_keras_object(critic_config)

        # Deserialize `Generator` object.
        generator_config = config.pop('generator')
        generator = tf.keras.saving.deserialize_keras_object(generator_config)

        return cls(
            # Deserialized critic.
            critic=critic,
            # Deserialized generator.
            generator=generator,
            # All other config entries (that didn't need serialization).
            **config
        )

    def compile(self, c_optimizer, g_optimizer):
        """
        """
        super().compile()

        # Optimizers, separate for the critic and the generator.
        self.c_optimizer = c_optimizer
        self.g_optimizer = g_optimizer

        # Critic's metrics: the wasserstein one, the gradient penalty and the
        # total one (a linear combination of the two).
        self.c_wass_loss_metric = Mean(name='c_wass_loss')
        self.c_gp_metric = Mean(name='c_gp')
        self.c_loss_metric = Mean(name='c_loss')

        # Generator's metric (Wasserstein).
        self.g_loss_metric = Mean(name='g_loss')

    def get_compile_config(self):
        """
        Equivalent to `get_config`, but for the compiling part. While
        `get_config` returned the config to create a new instance of the model
        at loading time, this does the equivalent operation but for the
        compiling operation. Objects here are automatically serialized but
        THEIR VARIABLES (if any) are NOT SAVED/LOADED, meaning that the
        optimizers' state is actually not saved (this can be done with
        checkpoints though).
        """
        # These parameters will be serialized at saving time.
        return {
            'c_optimizer': tf.keras.saving.serialize_keras_object(
                self.c_optimizer
            ),
            'g_optimizer': tf.keras.saving.serialize_keras_object(
                self.g_optimizer
            )
        }

    def compile_from_config(self, config):
        """
        Given the config returned by the `get_compile_config` method,
        runs an operation equivalent to compiling at model loading time, using
        the serialized objects returned as dict values by
        `get_compile_config`.
        """
        c_optimizer = tf.keras.utils.deserialize_keras_object(
            config['c_optimizer']
        )
        g_optimizer = tf.keras.utils.deserialize_keras_object(
            config['g_optimizer']
        )

        print(len(c_optimizer.variables))

        # Calls compile with the deserialized parameters
        self.compile(c_optimizer=c_optimizer, g_optimizer=g_optimizer)

    @property
    def metrics(self):
        """
        """
        return [
            self.c_loss_metric,
            self.c_wass_loss_metric,
            self.c_gp_metric,
            self.g_loss_metric
        ]

    def gradient_penalty(self, batch_size, real_images, fake_images):
        """
        """
        # For each (real_image, fake_image) pair, generate a random linear
        # interpolation (pixel-wise, in in tensities).
        alpha = tf.random.uniform(shape=(batch_size, 1, 1, 1))

        interpolated_images = (
            (fake_images - real_images) * alpha
            + real_images
        )

        with tf.GradientTape() as gp_tape:
            # The gradient must watch `interpolated_images` as we'll ge
            # differentiating the critic's predictions w.r.t. these.
            gp_tape.watch(interpolated_images)

            # Generate the critic's predictions over the interpolated images.
            pred = self.critic(interpolated_images, training=True)

        # Compute the gradients w.r.t. each pixel/channel of each interpolated
        # image.
        # Output shape: (batch_size, img_size, img_size, n_channels).
        grads = gp_tape.gradient(pred, [interpolated_images])[0]

        # Compute the norm of the gradient for each interpolated image. The
        # sum acts on the pixels/channels dimensions so as to get a tensor
        # of shape (batch_size,), on which the square root is applied
        # element-wise.
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))

        # Compute the gradient penalty as the mean square difference between
        # the norms (one for each interpolated image) and the value 1. The
        # mean is taken over the interpolated images (`batch_size` terms).
        gp = tf.reduce_mean((norm - 1.0) ** 2)

        return gp

    def train_step(self, real_images):
        """
        """
        # Infer the batch size from the input.
        # Note: use `tf.shape`` instead of the tensor's `.shape` method, as
        #       only the former works at the build time of the computational
        #       graph.
        batch_size = tf.shape(real_images)[0]

        # Perform a set number of training steps for the critic every training
        # step of the generator.
        for _ in range(self.critic_steps):
            # Generate random latent vectors of the appropriate latent
            # dimension from which the generator creates the fake images.
            random_latent_vectors = tf.random.normal(
                shape=(batch_size, self.latent_dim)
            )

            with tf.GradientTape() as tape:
                # Create the fake images with the generator.
                fake_images = self.generator(
                    random_latent_vectors, training=True
                )

                # Make predictions on the fake and real images with the
                # critic.
                fake_predictions = self.critic(fake_images, training=True)
                real_predictions = self.critic(real_images, training=True)

                # Compute the Wasserstein loss (it's just the difference of
                # the mean predictions on the fake and on the real images).
                c_wass_loss = (
                    tf.reduce_mean(fake_predictions)
                    - tf.reduce_mean(real_predictions)
                )

                # Compute the gradient penalty term.
                c_gp = self.gradient_penalty(
                    batch_size, real_images, fake_images
                )

                # Compute the total loss for the critic as a sum of the
                # Wassersten and the gradient penalty one, the latter with a
                # given relative weight.
                c_loss = c_wass_loss + self.gp_weight * c_gp

            # Compute the gradient of the critic's loss w.r.t. its weights.
            c_gradient = tape.gradient(
                c_loss, self.critic.trainable_variables
            )

            # Perform a gradient descent step for the critic's weights.
            self.c_optimizer.apply_gradients(
                zip(c_gradient, self.critic.trainable_variables)
            )

        # Perform a training step for the generator.
        random_latent_vectors = tf.random.uniform(
            shape=(batch_size, self.latent_dim)
        )

        with tf.GradientTape() as tape:
            # Create fake images from the latent vectors with the generator.
            fake_images = self.generator(random_latent_vectors, training=True)

            # Compute the critic's predictions for the fake images.
            fake_predictions = self.critic(fake_images, training=True)

            # Compute the Wasserstein loss for the generator.
            g_loss = - tf.reduce_mean(fake_predictions)

        # Compute the gradient of the generator's loss w.r.t. to its weights.
        g_gradient = tape.gradient(g_loss, self.generator.trainable_variables)

        # Perform a radient descent step for the generator's weights.
        self.g_optimizer.apply_gradients(
            zip(g_gradient, self.generator.trainable_weights)
        )

        # Update the critic's metrics.
        self.c_loss_metric.update_state(c_loss)
        self.c_wass_loss_metric.update_state(c_wass_loss)
        self.c_gp_metric.update_state(c_gp)

        # Update the generator's metrics.
        self.g_loss_metric.update_state(g_loss)

        # Return a dictionary with metric names and values for the current
        # training step.
        return {metric.name: metric.result() for metric in self.metrics}


class ConditionalWGANGP(tf.keras.Model):
    """
    Subclass of Keras `Model` implementing a conditional GAN with Wasserstein
    loss and gradient penalty. The architecture and algorithm is analogous to
    that of the `WGANGP` object, save the fact that one-hot encoded class
    labels are assumed to be passed as input in the training phase. These
    are reshaped appropriately so that they can be accepted as inputs by
    `CGANGenerator` and `CGANCritic` models.
    """
    def __init__(
        self,
        critic,
        generator,
        latent_dim,
        critic_steps,
        gp_weight
    ):
        """
        """
        super().__init__()

        self.critic = critic
        self.generator = generator

        self.latent_dim = latent_dim
        self.critic_steps = critic_steps
        self.gp_weight = gp_weight

    @staticmethod
    def expand_label_tensor(label_tensor, img_size=(64, 64)):
        """
        Expands each sample's one-hot encoded class label (a tensor
        with shape `(n_classes,)` to increase the rank by 2.
        The label's value is repeated along each of the new dimensions.

        In case of batches of samples, the sample shape remains the left-most
        one: `label_tensor` has shape `(batch_size, n_classes)` and the output
        will have shape `(batch_size, img_size[0], img_size[1], n_classes)`.
        """
        # Equivalent to using tf.newaxis.
        output = label_tensor[:, None, None, :]

        for i, size in enumerate(img_size):
            output = tf.repeat(
                output,
                repeats=size,
                axis=i+1
            )

        return output

    def compile(self, c_optimizer, g_optimizer):
        """
        """
        super().compile()

        # Optimizers, separate for the critic and the generator.
        self.c_optimizer = c_optimizer
        self.g_optimizer = g_optimizer

        # Critic's metrics: the wasserstein one, the gradient penalty and the
        # total one (a linear combination of the two).
        self.c_wass_loss_metric = Mean(name='c_wass_loss')
        self.c_gp_metric = Mean(name='c_gp')
        self.c_loss_metric = Mean(name='c_loss')

        # Generator's metric (Wasserstein).
        self.g_loss_metric = Mean(name='g_loss')

    @property
    def metrics(self):
        """
        """
        return [
            self.c_loss_metric,
            self.c_wass_loss_metric,
            self.c_gp_metric,
            self.g_loss_metric
        ]

    def gradient_penalty(
        self,
        batch_size,
        real_images,
        fake_images,
        image_one_hot_labels
    ):
        """
        """
        # For each (real_image, fake_image) pair, generate a random linear
        # interpolation (pixel-wise, in in tensities).
        alpha = tf.random.uniform(shape=(batch_size, 1, 1, 1))

        interpolated_images = (
            (fake_images - real_images) * alpha
            + real_images
        )

        with tf.GradientTape() as gp_tape:
            # The gradient must watch `interpolated_images` as we'll ge
            # differentiating the critic's predictions w.r.t. these.
            gp_tape.watch(interpolated_images)

            # Generate the critic's predictions over the interpolated images.
            pred = self.critic(
                [interpolated_images, image_one_hot_labels], training=True
            )

        # Compute the gradients w.r.t. each pixel/channel of each interpolated
        # image.
        # Output shape: (batch_size, img_size, img_size, n_channels).
        grads = gp_tape.gradient(pred, [interpolated_images])[0]

        # Compute the norm of the gradient for each interpolated image. The
        # sum acts on the pixels/channels dimensions so as to get a tensor
        # of shape (batch_size,), on which the square root is applied
        # element-wise.
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))

        # Compute the gradient penalty as the mean square difference between
        # the norms (one for each interpolated image) and the value 1. The
        # mean is taken over the interpolated images (`batch_size` terms).
        gp = tf.reduce_mean((norm - 1.0) ** 2)

        return gp

    def train_step(self, data):
        """
        """
        # Unpack the input data into images and one-hot encoded class labels.
        real_images, one_hot_labels = data

        image_one_hot_labels = self.expand_label_tensor(one_hot_labels)

        # Infer the batch size from the input.
        # Note: use `tf.shape`` instead of the tensor's `.shape` method, as
        #       only the former works at the build time of the computational
        #       graph.
        batch_size = tf.shape(real_images)[0]

        # Perform a set number of training steps for the critic every training
        # step of the generator.
        for _ in range(self.critic_steps):
            # Generate random latent vectors of the appropriate latent
            # dimension from which the generator creates the fake images.
            random_latent_vectors = tf.random.normal(
                shape=(batch_size, self.latent_dim)
            )

            with tf.GradientTape() as tape:
                # Create the fake images with the generator.
                fake_images = self.generator(
                    [random_latent_vectors, one_hot_labels], training=True
                )

                # Make predictions on the fake and real images with the
                # critic.
                fake_predictions = self.critic(
                    [fake_images, image_one_hot_labels], training=True)
                real_predictions = self.critic(
                    [real_images, image_one_hot_labels], training=True)

                # Compute the Wasserstein loss (it's just the difference of
                # the mean predictions on the fake and on the real images).
                c_wass_loss = (
                    tf.reduce_mean(fake_predictions)
                    - tf.reduce_mean(real_predictions)
                )

                # Compute the gradient penalty term.
                c_gp = self.gradient_penalty(
                    batch_size, real_images, fake_images, image_one_hot_labels
                )

                # Compute the total loss for the critic as a sum of the
                # Wassersten and the gradient penalty one, the latter with a
                # given relative weight.
                c_loss = c_wass_loss + self.gp_weight * c_gp

            # Compute the gradient of the critic's loss w.r.t. its weights.
            c_gradient = tape.gradient(
                c_loss, self.critic.trainable_variables
            )

            # Perform a gradient descent step for the critic's weights.
            self.c_optimizer.apply_gradients(
                zip(c_gradient, self.critic.trainable_variables)
            )

        # Perform a training step for the generator.
        random_latent_vectors = tf.random.uniform(
            shape=(batch_size, self.latent_dim)
        )

        with tf.GradientTape() as tape:
            # Create fake images from the latent vectors with the generator.
            fake_images = self.generator(
                [random_latent_vectors, one_hot_labels], training=True)

            # Compute the critic's predictions for the fake images.
            fake_predictions = self.critic(
                [fake_images, image_one_hot_labels], training=True)

            # Compute the Wasserstein loss for the generator.
            g_loss = - tf.reduce_mean(fake_predictions)

        # Compute the gradient of the generator's loss w.r.t. to its weights.
        g_gradient = tape.gradient(g_loss, self.generator.trainable_variables)

        # Perform a radient descent step for the generator's weights.
        self.g_optimizer.apply_gradients(
            zip(g_gradient, self.generator.trainable_weights)
        )

        # Update the critic's metrics.
        self.c_loss_metric.update_state(c_loss)
        self.c_wass_loss_metric.update_state(c_wass_loss)
        self.c_gp_metric.update_state(c_gp)

        # Update the generator's metrics.
        self.g_loss_metric.update_state(g_loss)

        # Return a dictionary with metric names and values for the current
        # training step.
        return {metric.name: metric.result() for metric in self.metrics}



